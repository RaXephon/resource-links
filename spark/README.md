###Spark

Spark is faster than Hadoop.
Hadoop: MapReduce, HDFS

Spark - has no HDFS, built to work with Hadoop. 
some say core of HDFS is hadoop.

Spark is better than mapreduce part of hadoop.

Many companies are so entrenched in Hadoop; hard to change directions.

Spark is faster than Hadoop.
Spark doesn't have to write to disk when running a job.
Spark uses in-memory caching.

RDD - think of these as our main data types.

using spark context to turn data array into RDD, means it is serialized.  we are able to partition it out.

PySpark SQL

exit()             # EXIT
